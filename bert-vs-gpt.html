<!DOCTYPE html>
<html lang="de">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BERT vs. GPT: Ein Vergleich - Innovate Solutions</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
    <style>
        body {
            font-family: 'Inter', sans-serif;
        }
        .nav-link.active {
            color: #2563EB; /* blue-600 */
            font-weight: 600;
        }
    </style>
</head>
<body class="bg-gray-50 text-gray-800">

    <!-- Header und Navigation -->
    <header class="bg-white shadow-md sticky top-0 z-50">
        <nav class="container mx-auto px-6 py-4 flex justify-between items-center">
            <a href="index.html" class="text-2xl font-bold text-blue-600">Innovate Solutions</a>
            <div class="hidden md:flex space-x-6">
                <a href="index.html" class="nav-link text-gray-600 hover:text-blue-600 transition duration-300">Startseite</a>
                <a href="about.html" class="nav-link text-gray-600 hover:text-blue-600 transition duration-300">Über uns</a>
                <a href="services.html" class="nav-link text-gray-600 hover:text-blue-600 transition duration-300">Dienstleistungen</a>
                <a href="history.html" class="nav-link text-gray-600 hover:text-blue-600 transition duration-300">KI-Geschichte</a>
                <a href="contact.html" class="nav-link text-gray-600 hover:text-blue-600 transition duration-300">Kontakt</a>
            </div>
            <button id="mobile-menu-button" class="md:hidden focus:outline-none">
                <svg class="w-6 h-6" fill="none" stroke="currentColor" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M4 6h16M4 12h16m-7 6h7"></path></svg>
            </button>
        </nav>
        <!-- Mobiles Menü -->
        <div id="mobile-menu" class="hidden md:hidden">
            <a href="index.html" class="block py-2 px-4 text-sm hover:bg-gray-100">Startseite</a>
            <a href="about.html" class="block py-2 px-4 text-sm hover:bg-gray-100">Über uns</a>
            <a href="services.html" class="block py-2 px-4 text-sm hover:bg-gray-100">Dienstleistungen</a>
            <a href="history.html" class="block py-2 px-4 text-sm hover:bg-gray-100">KI-Geschichte</a>
            <a href="contact.html" class="block py-2 px-4 text-sm hover:bg-gray-100">Kontakt</a>
        </div>
    </header>

    <main class="container mx-auto p-6 md:p-12">
        <!-- INHALT DER "BERT vs. GPT"-SEITE -->
        <section class="bg-white p-8 md:p-12 rounded-xl shadow-lg">
            <h1 class="text-4xl font-bold text-gray-900 mb-4">BERT vs. GPT: Zwei Seiten einer Medaille</h1>
            <p class="text-lg text-gray-500 mb-8">Ein Vergleich der beiden einflussreichsten Transformer-Architekturen.</p>

            <div class="prose prose-lg max-w-none">
                <p>Obwohl sowohl BERT (von Google) als auch GPT (von OpenAI) auf derselben revolutionären Transformer-Architektur basieren, verfolgen sie fundamental unterschiedliche Ansätze und sind für verschiedene Arten von Aufgaben optimiert. Sie zu verstehen bedeutet, die beiden dominanten Philosophien der modernen Sprachverarbeitung zu verstehen.</p>

                <h2 class="mt-10">Der Kernunterschied: Architektur und Trainingsziel</h2>
                <p>Der Hauptunterschied liegt darin, wie sie die Transformer-Architektur nutzen und was sie während des Trainings lernen sollen.</p>
                
                <div class="grid md:grid-cols-2 gap-8 my-8">
                    <div class="border border-gray-200 rounded-lg p-6">
                        <h3 class="text-2xl font-semibold text-blue-600 mb-3">BERT (Bidirectional Encoder Representations from Transformers)</h3>
                        <p><strong>Architektur:</strong> Nutzt nur den <strong>Encoder</strong>-Teil des Transformers. Der Encoder ist darauf ausgelegt, eine vollständige Eingabesequenz zu lesen und eine reichhaltige, kontextualisierte Repräsentation davon zu erstellen.</p>
                        <p class="mt-2"><strong>Trainingsziel: Masked Language Model (MLM).</strong> BERT bekommt einen Satz, in dem zufällig Wörter maskiert (versteckt) sind. Seine Aufgabe ist es, diese maskierten Wörter vorherzusagen, indem es den Kontext von <strong>links und rechts</strong> betrachtet. Dies zwingt das Modell, ein tiefes, bidirektionales Verständnis für die Struktur und Bedeutung von Sätzen zu entwickeln.</p>
                        <p class="mt-2"><strong>Stärke:</strong> Exzellent im <strong>Verständnis</strong> von Sprache. Ideal für Aufgaben wie Klassifikation, Stimmungsanalyse, Frage-Antwort-Systeme und Named Entity Recognition.</p>
                    </div>
                    <div class="border border-gray-200 rounded-lg p-6">
                        <h3 class="text-2xl font-semibold text-green-600 mb-3">GPT (Generative Pre-trained Transformer)</h3>
                        <p><strong>Architektur:</strong> Nutzt nur den <strong>Decoder</strong>-Teil des Transformers. Der Decoder ist darauf ausgelegt, eine Sequenz Wort für Wort zu generieren, basierend auf dem bisher erzeugten Text.</p>
                        <p class="mt-2"><strong>Trainingsziel: Autoregressives Sprachmodell.</strong> GPTs Aufgabe ist es, immer nur das <strong>nächste Wort</strong> in einer Sequenz vorherzusagen, basierend auf allen vorhergehenden Wörtern. Es schaut also nur nach links (in die Vergangenheit).</p>
                        <p class="mt-2"><strong>Stärke:</strong> Exzellent in der <strong>Generierung</strong> von Sprache. Ideal für Aufgaben wie das Schreiben von Texten, Zusammenfassungen, Dialogsysteme (Chatbots) und kreatives Schreiben.</p>
                    </div>
                </div>

                <h2 class="mt-10">Eine Analogie: Der Detektiv vs. der Autor</h2>
                <p>Man kann sich den Unterschied wie folgt vorstellen:</p>
                <ul>
                    <li><strong>BERT ist wie ein Detektiv,</strong> der einen vollständigen Text mit Lücken analysiert. Um die fehlenden Wörter zu ergänzen, muss er den gesamten Kontext – vor und nach der Lücke – verstehen. Sein Ziel ist die Analyse und das Verständnis des Vorhandenen.</li>
                    <li><strong>GPT ist wie ein Autor,</strong> der einen Satz schreibt. Um das nächste Wort zu wählen, schaut er auf alles, was er bisher geschrieben hat, und überlegt, wie die Geschichte am plausibelsten weitergeht. Sein Ziel ist die kreative Fortsetzung und Generierung von Neuem.</li>
                </ul>

                <h2 class="mt-10">Zusammenfassung im Überblick</h2>
                <table class="w-full text-left border-collapse mt-6">
                    <thead>
                        <tr>
                            <th class="border-b-2 p-4">Merkmal</th>
                            <th class="border-b-2 p-4 text-blue-600">BERT</th>
                            <th class="border-b-2 p-4 text-green-600">GPT</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td class="border-b p-4 font-semibold">Primärzweck</td>
                            <td class="border-b p-4">Sprachverständnis</td>
                            <td class="border-b p-4">Sprachgenerierung</td>
                        </tr>
                        <tr>
                            <td class="border-b p-4 font-semibold">Architektur</td>
                            <td class="border-b p-4">Encoder-Only</td>
                            <td class="border-b p-4">Decoder-Only</td>
                        </tr>
                        <tr>
                            <td class="border-b p-4 font-semibold">Kontext</td>
                            <td class="border-b p-4">Bidirektional (Links & Rechts)</td>
                            <td class="border-b p-4">Unidirektional (Nur Links)</td>
                        </tr>
                        <tr>
                            <td class="border-b p-4 font-semibold">Typische Anwendung</td>
                            <td class="border-b p-4">Analyse, Klassifikation, Suche</td>
                            <td class="border-b p-4">Chat, Textkreation, Zusammenfassung</td>
                        </tr>
                         <tr>
                            <td class="border-b p-4 font-semibold">Ansatz</td>
                            <td class="border-b p-4">Meist Fine-Tuning für spezifische Aufgaben</td>
                            <td class="border-b p-4">Meist In-Context Learning via Prompting</td>
                        </tr>
                    </tbody>
                </table>

                <h2 class="mt-10">Fazit</h2>
                <p>BERT und GPT sind keine direkten Konkurrenten, sondern unterschiedliche Werkzeuge, die aus derselben technologischen Revolution hervorgegangen sind. Während BERT die Art und Weise, wie Maschinen Sprache verstehen, revolutioniert hat, hat GPT die Art und Weise, wie Maschinen Sprache erzeugen, neu definiert. Die Entwicklung beider Modellfamilien hat das Feld der künstlichen Intelligenz maßgeblich vorangetrieben und die Grundlagen für die heutigen fortschrittlichen KI-Systeme geschaffen.</p>
            </div>
        </section>
    </main>
    
    <!-- Footer -->
    <footer class="bg-white mt-16">
        <div class="container mx-auto px-6 py-8 text-center text-gray-600">
            <p>&copy; 2025 Innovate Solutions. Alle Rechte vorbehalten.</p>
        </div>
    </footer>

    <script>
        // Skript für das mobile Menü
        document.getElementById('mobile-menu-button').addEventListener('click', function() {
            document.getElementById('mobile-menu').classList.toggle('hidden');
        });
    </script>
</body>
</html>
